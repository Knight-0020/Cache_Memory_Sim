================================================================================
              SINGLE-LEVEL CACHE MEMORY SYSTEM - DETAILED DOCUMENTATION
                     For Lab Record / Viva Preparation (EL-1)
================================================================================

================================================================================
1. INTRODUCTION TO CACHE MEMORY
================================================================================

What is Cache Memory?
---------------------
Cache memory is a small, high-speed memory positioned between the CPU and main
memory (RAM). It stores copies of frequently accessed data to reduce the average
time required to access data from main memory.

Why is Cache Memory Needed?
---------------------------
The "Memory Wall" problem: CPU speeds have increased much faster than memory
speeds. A modern CPU can execute billions of instructions per second, but
fetching data from RAM takes 100+ CPU cycles.

Performance Impact:
- Without cache: CPU waits ~100 cycles for each memory access
- With cache hit: CPU waits ~1-2 cycles
- Hit rate of 95% → Average access time ≈ 6 cycles (massive improvement!)

Locality of Reference:
- TEMPORAL LOCALITY: If data is accessed, it will likely be accessed again soon
  Example: Loop counter, function return address
  
- SPATIAL LOCALITY: If data at address X is accessed, data at X+1, X+2... 
  will likely be accessed soon
  Example: Array traversal, instruction fetch

================================================================================
2. CACHE ORGANIZATION TYPES
================================================================================

This project implements TWO cache organizations:

2.1 Direct-Mapped Cache
-----------------------
Each memory address maps to EXACTLY ONE cache line (set).

Mapping: Set = (Address / Block_Size) mod Number_of_Sets

Example: Address 0x124 with 32 sets, 32-byte blocks
         Set = (0x124 / 32) mod 32 = 9 mod 32 = 9

Advantages:
- Simplest hardware implementation
- Fastest lookup (only one location to check)
- Lowest power consumption

Disadvantages:
- CONFLICT MISSES: If two frequently accessed addresses map to the same
  set, they keep evicting each other (thrashing)

2.2 2-Way Set-Associative Cache
-------------------------------
Each memory address can be stored in ONE OF TWO locations (ways).

Mapping: Set = (Address / Block_Size) mod Number_of_Sets
         Way = Either 0 or 1 (determined by LRU on miss)

Example: Address 0x124 with 16 sets, 32-byte blocks
         Set = (0x124 / 32) mod 16 = 9 mod 16 = 9
         Can be in Way 0 or Way 1 of Set 9

Advantages:
- Reduces conflict misses significantly
- Better hit rate than direct-mapped

Disadvantages:
- More complex hardware (must check 2 tags in parallel)
- Needs replacement policy (LRU)
- Higher power consumption

================================================================================
3. CACHE PARAMETERS (THIS DESIGN)
================================================================================

Common Parameters:
------------------
┌───────────────────────────────────────┐
│ Parameter          │ Value            │
├───────────────────────────────────────┤
│ Address Width      │ 32 bits          │
│ Cache Size         │ 1 KB (1024 bytes)│
│ Block Size         │ 32 bytes         │
│ Block Bits         │ 256 bits         │
│ Words per Block    │ 8 (32-bit words) │
│ Offset Bits        │ 5 (log2(32))     │
│ CPU Data Width     │ 32 bits          │
└───────────────────────────────────────┘

Direct-Mapped Specific:
-----------------------
┌───────────────────────────────────────┐
│ Parameter          │ Value            │
├───────────────────────────────────────┤
│ Number of Sets     │ 32               │
│ Index Bits         │ 5 (log2(32))     │
│ Tag Bits           │ 22 (32-5-5)      │
└───────────────────────────────────────┘

2-Way Set-Associative Specific:
-------------------------------
┌───────────────────────────────────────┐
│ Parameter          │ Value            │
├───────────────────────────────────────┤
│ Number of Sets     │ 16               │
│ Ways per Set       │ 2                │
│ Index Bits         │ 4 (log2(16))     │
│ Tag Bits           │ 23 (32-4-5)      │
│ LRU Bits           │ 1 per set        │
└───────────────────────────────────────┘

================================================================================
4. ADDRESS BREAKDOWN (DETAILED)
================================================================================

4.1 Direct-Mapped Address Format
--------------------------------

32-bit Address: addr[31:0]

    ┌────────────────────┬─────────┬─────────┐
    │        TAG         │  INDEX  │ OFFSET  │
    │     addr[31:10]    │addr[9:5]│addr[4:0]│
    │      22 bits       │ 5 bits  │ 5 bits  │
    └────────────────────┴─────────┴─────────┘

TAG (22 bits): Stored in cache to identify which memory block is cached
INDEX (5 bits): Selects which of the 32 sets to access
OFFSET (5 bits): Selects which byte within the 32-byte block

Calculation Example:
Address = 0x0000_04A8

Binary: 0000_0000_0000_0000_0000_0100_1010_1000

Tag    = addr[31:10] = 0000_0000_0000_0000_0000_01 = 0x000001
Index  = addr[9:5]   = 00101 = 5
Offset = addr[4:0]   = 01000 = 8

This means:
- Look in Set 5
- Compare tag with 0x000001
- If match, return byte at offset 8 in the block

4.2 2-Way Set-Associative Address Format
----------------------------------------

32-bit Address: addr[31:0]

    ┌─────────────────────┬─────────┬─────────┐
    │         TAG         │  INDEX  │ OFFSET  │
    │     addr[31:9]      │addr[8:5]│addr[4:0]│
    │       23 bits       │ 4 bits  │ 5 bits  │
    └─────────────────────┴─────────┴─────────┘

TAG (23 bits): Stored in cache to identify which memory block is cached
INDEX (4 bits): Selects which of the 16 sets to access
OFFSET (5 bits): Selects which byte within the 32-byte block

Calculation Example:
Address = 0x0000_04A8

Tag    = addr[31:9]  = 0x000002 (different because index is smaller)
Index  = addr[8:5]   = 0101 = 5
Offset = addr[4:0]   = 01000 = 8

This means:
- Look in Set 5
- Compare tag with 0x000002 in BOTH Way 0 and Way 1
- If either matches, it's a hit

================================================================================
5. CACHE LINE STRUCTURE
================================================================================

5.1 Direct-Mapped Cache Line
----------------------------

Each of the 32 sets contains:

    ┌───────┬───────┬────────────┬───────────────────────────────────────────┐
    │ VALID │ DIRTY │    TAG     │                  DATA BLOCK               │
    │ 1 bit │ 1 bit │  22 bits   │                 256 bits                  │
    └───────┴───────┴────────────┴───────────────────────────────────────────┘
                                 │                                           │
                                 │ Word7│Word6│Word5│Word4│Word3│Word2│Word1│Word0│
                                 │[255:224]│...│...│...│...│...│...│[31:0]│

VALID: 1 = line contains valid data, 0 = empty or stale
DIRTY: 1 = data modified but not written to memory, 0 = clean
TAG: Identifies which memory block is cached here
DATA: 32 bytes = 8 words of 32 bits each

5.2 2-Way Set-Associative Cache Line
------------------------------------

Each of the 16 sets contains TWO ways plus an LRU bit:

    ┌───────────────────────────────────────────────────────────────────────────┐
    │                               SET N                                        │
    ├───────────────────────────────────┬───────────────────────────────────┬───┤
    │              WAY 0                │              WAY 1                │LRU│
    ├───────┬───────┬──────┬────────────┼───────┬───────┬──────┬────────────┼───┤
    │ VALID │ DIRTY │ TAG  │    DATA    │ VALID │ DIRTY │ TAG  │    DATA    │bit│
    │ 1 bit │ 1 bit │23bit │  256 bits  │ 1 bit │ 1 bit │23bit │  256 bits  │ 1 │
    └───────┴───────┴──────┴────────────┴───────┴───────┴──────┴────────────┴───┘

LRU bit meaning:
- LRU = 0: Way 0 is Least Recently Used (will be evicted next)
- LRU = 1: Way 1 is Least Recently Used (will be evicted next)

================================================================================
6. READ HIT OPERATION (Step-by-Step)
================================================================================

Scenario: CPU reads from address 0x0000_0104

Step 1: Address Decode
        - Offset = 0x04 (byte 4 in block)
        - Index = 8 (for DM) or 8 (for SA)
        - Tag = 0x000000

Step 2: Cache Lookup
        - Access Set 8
        - Compare stored tag with address tag

Step 3: Hit Detection
        DM:  valid[8] AND (tag[8] == 0x000000) → TRUE
        SA:  (valid0[8] AND (tag0[8] == 0x000000)) OR
             (valid1[8] AND (tag1[8] == 0x000000)) → TRUE

Step 4: Data Extraction
        - Block contains 32 bytes
        - Offset 0x04 means Word 1 (offset[4:2] = 1)
        - Return data[8][63:32]

Step 5: Response
        - cpu_rdata = extracted word
        - cpu_resp = 1
        - hit = 1

Step 6: LRU Update (SA only)
        - If hit in Way 0: LRU[8] = 1 (Way 1 becomes LRU)
        - If hit in Way 1: LRU[8] = 0 (Way 0 becomes LRU)

Timing: ~2 clock cycles (IDLE → COMPARE → HIT → RESP)

================================================================================
7. READ MISS OPERATION (Step-by-Step)
================================================================================

Scenario: CPU reads from address 0x0000_0500 (not in cache)

Step 1: Address Decode
        - Offset = 0x00
        - Index = 8 (maps to Set 8)
        - Tag = 0x000001

Step 2: Cache Lookup
        - Access Set 8
        - Compare stored tag with address tag → NO MATCH

Step 3: Miss Detection
        - cache_hit = FALSE
        - Need to evict current line and fetch new block

Step 4: Victim Selection
        DM:  Victim is always Set 8 (no choice)
        SA:  Victim is way indicated by LRU[8]

Step 5: Check Dirty Bit
        - IF dirty_arr[victim] == 1:
          - Need to write back victim block to memory first
          - GOTO Step 6a (Writeback)
        - ELSE:
          - GOTO Step 6b (Allocate)

Step 6a: Writeback (if victim is dirty)
        - Reconstruct victim address: {old_tag, index, 5'b00000}
        - mem_req = 1, mem_rw = 1 (write)
        - mem_addr = victim_address
        - mem_wdata = victim_block (256 bits)
        - Wait for mem_resp

Step 6b: Allocate (fetch new block)
        - Block address = {req_addr[31:5], 5'b00000}
        - mem_req = 1, mem_rw = 0 (read)
        - mem_addr = block_address
        - Wait for mem_resp

Step 7: Update Cache
        - valid[index] = 1
        - dirty[index] = 0 (just fetched, clean)
        - tag[index] = new_tag
        - data[index] = mem_rdata (256 bits)

Step 8: Response
        - Extract requested word from fetched block
        - cpu_rdata = word
        - cpu_resp = 1

Timing: 
- Clean miss: ~8 cycles (includes memory latency)
- Dirty miss: ~14 cycles (writeback + fetch)

================================================================================
8. WRITE HIT OPERATION (Write-Back Policy)
================================================================================

Scenario: CPU writes 0xDEADBEEF to address 0x0000_0104 (already in cache)

Step 1: Address Decode
        - Same as read

Step 2: Cache Lookup
        - Hit detected

Step 3: Data Update
        - Get current block from cache
        - Modify word at offset with byte strobes
        - Store updated block back to cache array

Step 4: Dirty Bit Set
        - dirty[index] = 1
        - This marks the block as modified

Step 5: Response
        - cpu_resp = 1
        - hit = 1

IMPORTANT: Memory is NOT updated on write hit!
The modified data stays only in cache until eviction.
This is the essence of "Write-Back" policy.

Timing: ~2 clock cycles

================================================================================
9. WRITE MISS OPERATION (Write-Allocate Policy)
================================================================================

Scenario: CPU writes 0xCAFEBABE to address 0x0000_0800 (not in cache)

Step 1: Address Decode & Miss Detection
        - Same as read miss

Step 2: Victim Selection & Writeback (if dirty)
        - Same as read miss

Step 3: Allocate (fetch block from memory)
        - Fetch the 32-byte block containing 0x800
        - Even though we're writing, we need the OTHER bytes in the block

Step 4: Modify Block
        - Take fetched block
        - Update the specific word with write data
        - Apply byte strobes for partial writes

Step 5: Store in Cache
        - valid[index] = 1
        - dirty[index] = 1  ← DIFFERENT FROM READ MISS!
        - tag[index] = new_tag
        - data[index] = modified_block

Step 6: Response
        - cpu_resp = 1
        - hit = 0 (it was a miss)

IMPORTANT: Write-Allocate means we ALWAYS fetch the block first,
then modify it in cache. This contrasts with "No-Write-Allocate"
where we'd write directly to memory without caching.

Why Write-Allocate?
- Exploits spatial locality for writes
- If you write to one byte, you'll likely write to nearby bytes soon
- Commonly paired with Write-Back policy

================================================================================
10. LRU REPLACEMENT MECHANISM (2-Way Only)
================================================================================

The LRU (Least Recently Used) algorithm evicts the block that was
accessed longest ago.

For 2-way set-associative, only 1 bit per set is needed:

    LRU[set] = 0: Way 0 is LRU (evict Way 0 on miss)
    LRU[set] = 1: Way 1 is LRU (evict Way 1 on miss)

LRU Update Rules:
-----------------
After ANY access (read or write) to a way:
    Access Way 0 → LRU[set] = 1 (Way 1 becomes LRU)
    Access Way 1 → LRU[set] = 0 (Way 0 becomes LRU)

Example Sequence:
-----------------
Initial: Set 5 is empty, LRU[5] = 0

1. Read 0x0A0 → Miss, allocate to Way 0 (LRU says Way 0)
   LRU[5] = 1 (Way 1 is now LRU)

2. Read 0x2A0 → Miss, allocate to Way 1 (LRU says Way 1)
   LRU[5] = 0 (Way 0 is now LRU)

3. Read 0x0A0 → Hit in Way 0
   LRU[5] = 1 (Way 1 is now LRU)

4. Read 0x4A0 → Miss, evict Way 1 (LRU says Way 1)
   0x2A0 is evicted, 0x4A0 takes its place
   LRU[5] = 0 (Way 0 is now LRU)

5. Read 0x2A0 → Miss! (was evicted in step 4)

================================================================================
11. FSM STATE DESCRIPTIONS
================================================================================

┌────────────────┬───────────────────────────────────────────────────────────┐
│ State          │ Description                                                │
├────────────────┼───────────────────────────────────────────────────────────┤
│ S_IDLE         │ Waiting for CPU request. cpu_ready = 1.                    │
│                │ On cpu_req: latch address/data, transition to COMPARE.     │
├────────────────┼───────────────────────────────────────────────────────────┤
│ S_COMPARE      │ Perform tag comparison. Determine hit or miss.             │
│                │ For SA: also determine which way (hit or victim).          │
│                │ Transition: HIT if match, MISS_CHECK if no match.          │
├────────────────┼───────────────────────────────────────────────────────────┤
│ S_HIT          │ Handle cache hit.                                          │
│                │ Read: extract word from block.                             │
│                │ Write: update block and set dirty bit.                     │
│                │ Update LRU (SA only). Transition to RESP.                  │
├────────────────┼───────────────────────────────────────────────────────────┤
│ S_MISS_CHECK   │ Determine if victim block is dirty.                        │
│                │ Dirty: transition to WRITEBACK_INIT.                       │
│                │ Clean: transition to ALLOCATE_INIT.                        │
├────────────────┼───────────────────────────────────────────────────────────┤
│ S_WRITEBACK_   │ Start writeback to memory.                                 │
│ INIT           │ Wait for mem_ready, then assert mem_req with write.        │
│                │ Transition to WRITEBACK.                                   │
├────────────────┼───────────────────────────────────────────────────────────┤
│ S_WRITEBACK    │ Wait for memory write to complete.                         │
│                │ On mem_resp: transition to ALLOCATE_INIT.                  │
├────────────────┼───────────────────────────────────────────────────────────┤
│ S_ALLOCATE_    │ Start fetching new block from memory.                      │
│ INIT           │ Wait for mem_ready, then assert mem_req with read.         │
│                │ Transition to ALLOCATE.                                    │
├────────────────┼───────────────────────────────────────────────────────────┤
│ S_ALLOCATE     │ Wait for memory read to complete.                          │
│                │ On mem_resp: transition to UPDATE.                         │
├────────────────┼───────────────────────────────────────────────────────────┤
│ S_UPDATE       │ Update cache arrays with new block.                        │
│                │ Set valid = 1, tag = new_tag.                              │
│                │ For write: modify block and set dirty = 1.                 │
│                │ For read: set dirty = 0.                                   │
│                │ Update LRU (SA only). Transition to RESP.                  │
├────────────────┼───────────────────────────────────────────────────────────┤
│ S_RESP         │ Send response to CPU.                                      │
│                │ cpu_resp = 1, cpu_ready = 1.                               │
│                │ Transition to IDLE.                                        │
└────────────────┴───────────────────────────────────────────────────────────┘

================================================================================
12. TIMING DIAGRAMS
================================================================================

12.1 Read Hit Timing
--------------------

     clk: _|‾|_|‾|_|‾|_|‾|_|‾|_|‾|_
                                     
cpu_req:  ______|‾‾‾|______________
                                     
   state: IDLE  |CMP|HIT|RSP|IDLE
                                     
cpu_resp: _______________|‾‾‾|_____
                                     
 cpu_rdy: ‾‾‾‾‾‾|___|‾‾‾‾‾‾‾‾‾‾‾‾‾‾

Total: ~3 clock cycles

12.2 Read Miss (Clean Victim) Timing
------------------------------------

     clk: _|‾|_|‾|_|‾|_|‾|_|‾|_|‾|_|‾|_|‾|_|‾|_|‾|_
                                                     
cpu_req:  ______|‾‾‾|________________________________
                                                     
   state: IDLE|CMP|MCK|AIN|ALLOC...|UPD|RSP|IDLE
                                                     
 mem_req: _________|‾‾‾|_____________________________
                                                     
mem_resp: _____________________|‾‾‾|_________________
                                                     
cpu_resp: _____________________________|‾‾‾|_________

Total: ~8 clock cycles (includes 2-cycle memory latency)

12.3 Read Miss (Dirty Victim) Timing
------------------------------------

     clk: _|‾|_|‾|_|‾|_|‾|_|‾|_|‾|_|‾|_|‾|_|‾|_|‾|_|‾|_|‾|_|‾|_
                                                                 
cpu_req:  ______|‾‾‾|____________________________________________
                                                                 
   state: IDLE|CMP|MCK|WBI|WB...|AIN|ALLOC...|UPD|RSP|IDLE
                                                                 
 mem_req: _________|‾‾‾|_____|‾‾‾|_______________________________
 (write)           ^^^^       (read)
                                                                 
mem_resp: _______________|‾‾‾|___________|‾‾‾|___________________
                                                                 
cpu_resp: _________________________________________|‾‾‾|_________

Total: ~14 clock cycles (writeback + fetch)

================================================================================
13. WORD EXTRACTION FROM BLOCK
================================================================================

The 32-byte (256-bit) block stores 8 words:

    Block = [Word7][Word6][Word5][Word4][Word3][Word2][Word1][Word0]
            [255:224][223:192][191:160][159:128][127:96][95:64][63:32][31:0]

Word selection is done using offset bits [4:2]:

    Offset[4:2] = 0 (000) → Word0 = block[31:0]
    Offset[4:2] = 1 (001) → Word1 = block[63:32]
    Offset[4:2] = 2 (010) → Word2 = block[95:64]
    Offset[4:2] = 3 (011) → Word3 = block[127:96]
    Offset[4:2] = 4 (100) → Word4 = block[159:128]
    Offset[4:2] = 5 (101) → Word5 = block[191:160]
    Offset[4:2] = 6 (110) → Word6 = block[223:192]
    Offset[4:2] = 7 (111) → Word7 = block[255:224]

Verilog Implementation:
-----------------------
function [31:0] get_word;
    input [255:0] block;
    input [2:0] word_sel;  // offset[4:2]
    begin
        case (word_sel)
            3'd0: get_word = block[31:0];
            3'd1: get_word = block[63:32];
            3'd2: get_word = block[95:64];
            3'd3: get_word = block[127:96];
            3'd4: get_word = block[159:128];
            3'd5: get_word = block[191:160];
            3'd6: get_word = block[223:192];
            3'd7: get_word = block[255:224];
        endcase
    end
endfunction

================================================================================
14. BYTE STROBES FOR PARTIAL WRITES
================================================================================

The cpu_wstrb signal enables byte-level writes:

    cpu_wstrb[3:0] = Byte enable for each byte in the 32-bit word
    
    wstrb = 4'b0001 → Write byte 0 only (bits [7:0])
    wstrb = 4'b0010 → Write byte 1 only (bits [15:8])
    wstrb = 4'b0100 → Write byte 2 only (bits [23:16])
    wstrb = 4'b1000 → Write byte 3 only (bits [31:24])
    wstrb = 4'b1111 → Write all 4 bytes (full word)
    wstrb = 4'b0011 → Write bytes 0 and 1 (halfword)

Merge Logic:
-----------
For each byte position:
    new_byte = wstrb[i] ? cpu_wdata[i*8+7:i*8] : old_data[i*8+7:i*8]

Example:
- Old word: 0x12345678
- Write data: 0xFFFFFFFF
- Strobe: 4'b0001
- Result: 0x123456FF (only byte 0 changed)

================================================================================
15. WHY SINGLE-LEVEL CACHE?
================================================================================

This project implements a SINGLE-LEVEL cache for these reasons:

1. ACADEMIC CLARITY
   - Multi-level caches (L1/L2/L3) add layers of complexity
   - Understanding one level thoroughly is prerequisite
   - Easier to trace and debug

2. CONCEPTS FOCUS
   - All key concepts present: hit/miss, write policies, replacement
   - Adding levels doesn't add new concepts, just complexity
   - Same principles apply to each level

3. VERIFICATION SIMPLICITY
   - Waveforms are cleaner to analyze
   - State machine is traceable
   - Test cases are more intuitive

4. RESOURCE EFFICIENCY
   - Simpler for FPGA/ASIC implementation
   - Lower simulation time
   - Fits academic timeframe

Real-World Context:
------------------
Modern CPUs use 3+ cache levels:
- L1: ~32KB, ~4 cycles, split I-cache/D-cache
- L2: ~256KB, ~12 cycles, unified
- L3: ~8MB, ~40 cycles, shared among cores

The techniques in this project apply to ALL levels.

================================================================================
16. HOW TO RUN SIMULATION
================================================================================

Prerequisites:
--------------
- Icarus Verilog (iverilog) installed
- GTKWave (optional, for waveforms)

Installing Icarus Verilog on Windows:
-------------------------------------
1. Download from: http://bleyer.org/icarus/
2. IMPORTANT: Install to a path WITHOUT SPACES!
   - WRONG: C:\Program Files\iverilog  (will NOT work!)
   - CORRECT: C:\iverilog
3. Add C:\iverilog\bin to your PATH environment variable
4. Restart terminal after installation
5. Verify: iverilog -v

Using Makefile:
---------------
    # Compile and run simulation
    make sim
    
    # View waveforms (requires GTKWave)
    make wave
    
    # Run Direct-Mapped cache
    make sim_dm
    
    # Run Set-Associative cache (default)
    make sim_sa
    
    # Clean generated files
    make clean

Manual Commands:
----------------
    # Compile (Set-Associative)
    iverilog -g2012 -I rtl -o sim tb/tb_cache_system.v rtl/cache_top.v \
             rtl/set_associative_cache.v rtl/direct_mapped_cache.v rtl/main_memory.v
    
    # Run
    vvp sim
    
    # View waveforms
    gtkwave cache_system.vcd

Switching Cache Types:
----------------------
Edit rtl/cache_top.v and change the define:

    `define CACHE_TYPE_DM    // For Direct-Mapped
    `define CACHE_TYPE_SA    // For 2-Way Set-Associative (default)

================================================================================
17. EXPECTED OUTPUT AND WAVEFORM BEHAVIOR
================================================================================

Console Output Pattern:
-----------------------
============================================================
Cache Memory System - Comprehensive Testbench
============================================================
Cache Type: 2-WAY SET-ASSOCIATIVE
  Sets: 16, Ways: 2, Block Size: 32 bytes
============================================================

--- Reset Complete ---

============================================================
TEST A: Compulsory Miss then Hit (Same Block)
============================================================

A.1: Read 0x100 - Expect MISS (compulsory)
[READ]  Addr=0x00000100, Data=0x00000100, Hit=0, State=9, Time=...

A.2: Read 0x104 - Expect HIT (same block)
[READ]  Addr=0x00000104, Data=0x00000104, Hit=1, State=9, Time=...

... (more tests) ...

============================================================
FINAL RESULTS
============================================================
Total Hits:   XX
Total Misses: YY
Hit Rate:     ZZ%
------------------------------------------------------------
*** ALL TESTS PASSED ***

Waveform Observations:
----------------------
1. COMPULSORY MISS:
   - dbg_miss pulses HIGH
   - State goes: IDLE → COMPARE → MISS_CHECK → ALLOCATE_INIT → 
                 ALLOCATE → UPDATE → RESP → IDLE
   - mem_req pulses during ALLOCATE_INIT

2. HIT:
   - dbg_hit pulses HIGH
   - State goes: IDLE → COMPARE → HIT → RESP → IDLE
   - Much shorter than miss!

3. DIRTY WRITEBACK:
   - dbg_writeback pulses HIGH
   - State includes: WRITEBACK_INIT → WRITEBACK
   - Two memory transactions visible (write then read)

4. LRU UPDATE (SA):
   - dbg_lru toggles after each access
   - dbg_selected_way shows which way was accessed

================================================================================
18. COMMON VIVA QUESTIONS
================================================================================

Q1: What is a cache hit?
A: When the requested data is found in the cache. Valid bit is 1 AND tag matches.

Q2: What is a cache miss?
A: When the requested data is NOT in the cache. Either invalid or tag mismatch.

Q3: What are the three types of cache misses?
A: 
- COMPULSORY: First access to a block (unavoidable)
- CAPACITY: Cache is too small to hold all needed blocks
- CONFLICT: Two blocks map to same set (DM and low-associativity)

Q4: Explain write-back vs write-through.
A: 
- Write-Through: Write to both cache AND memory on every write
- Write-Back: Write only to cache, update memory on eviction
  Write-Back is faster but requires dirty bits.

Q5: What is the purpose of the dirty bit?
A: Indicates if cached data differs from memory. On eviction, dirty blocks 
   must be written back to memory to prevent data loss.

Q6: Why use write-allocate with write-back?
A: They work well together. Write-allocate brings the block into cache,
   then write-back keeps it there without immediate memory writes.
   This exploits both temporal and spatial locality for writes.

Q7: How does LRU work in 2-way cache?
A: With 2 ways, LRU needs only 1 bit per set. The bit indicates which 
   way was accessed LESS recently. On miss, evict the LRU way.

Q8: Why is direct-mapped faster than set-associative?
A: Only one tag comparison needed vs. two (or more) in parallel.
   No LRU logic required. Simpler control logic.

Q9: Why does set-associative have better hit rate?
A: Reduces conflict misses. Two addresses with same index can now 
   coexist in different ways.

Q10: What happens on a dirty read miss?
A: Three main steps:
    1. Write dirty victim block to memory (writeback)
    2. Fetch new block from memory (allocate)
    3. Return requested word to CPU

================================================================================
19. DESIGN LIMITATIONS
================================================================================

1. Single Outstanding Request
   - Only one request processed at a time
   - No pipelining
   - Real caches support multiple outstanding requests

2. No Prefetching
   - Only fetches data on demand
   - Real caches prefetch likely-needed blocks

3. Simple LRU
   - True LRU for higher associativity requires more bits
   - Real caches use pseudo-LRU or tree-based LRU

4. Fixed Block Size
   - 32 bytes is relatively small
   - Modern caches use 64-128 bytes

5. No Critical Word First
   - Fetches entire block before responding
   - Real caches return requested word first, then fill rest

6. No Sub-blocking
   - Entire block is valid or invalid
   - Some caches have per-word valid bits

================================================================================
20. GLOSSARY
================================================================================

Block/Line: Unit of data transfer between cache and memory (32 bytes here)
Cache Hit: Requested data found in cache
Cache Miss: Requested data not in cache
Compulsory Miss: First access to a block (cold start miss)
Conflict Miss: Miss due to multiple addresses mapping to same set
Dirty Bit: Indicates cached data differs from memory
Direct-Mapped: Each address maps to exactly one cache line
Index: Address bits selecting the cache set
LRU: Least Recently Used replacement policy
Offset: Address bits selecting byte within block
Set: A row in the cache (may contain multiple ways)
Set-Associative: Each address can map to one of N ways in a set
Tag: Address bits stored in cache for identification
Valid Bit: Indicates cache line contains valid data
Way: A column in a set-associative cache
Write-Allocate: On write miss, fetch block then modify
Write-Back: Update only cache on write, memory on eviction
Write-Through: Update both cache and memory on write

================================================================================
END OF DOCUMENTATION
================================================================================
